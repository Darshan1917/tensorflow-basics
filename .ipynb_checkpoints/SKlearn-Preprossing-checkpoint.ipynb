{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pandas_datareader\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87 52 48]\n",
      " [80  1 52]\n",
      " [47 27 83]\n",
      " [63 13 59]\n",
      " [ 2 77 68]\n",
      " [62 54 13]\n",
      " [59 97 17]\n",
      " [80 72  3]\n",
      " [98 73 94]\n",
      " [35 23 88]]\n"
     ]
    }
   ],
   "source": [
    "data = np.random.randint(1,100,size=(10,3))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "sclar_ini = MinMaxScaler()  # create an instance of the Preprosseing step\n",
    "print(sclar_ini)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "[[ 0.88541667  0.53125     0.49450549]\n",
      " [ 0.8125      0.          0.53846154]\n",
      " [ 0.46875     0.27083333  0.87912088]\n",
      " [ 0.63541667  0.125       0.61538462]\n",
      " [ 0.          0.79166667  0.71428571]\n",
      " [ 0.625       0.55208333  0.10989011]\n",
      " [ 0.59375     1.          0.15384615]\n",
      " [ 0.8125      0.73958333  0.        ]\n",
      " [ 1.          0.75        1.        ]\n",
      " [ 0.34375     0.22916667  0.93406593]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dumapath\\AppData\\Local\\conda\\conda\\envs\\my_root\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Fit the data to it and transform it \n",
    "\n",
    "scaler = sclar_ini.fit(data)\n",
    "standardized_X = scaler.transform(data)\n",
    "print (scaler)\n",
    "print(standardized_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler -- the max value in the column is made 1 and min value is made 0 and the values are fit in between them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We fit the instance to the training data and then apply transformation (transform) to train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standardization \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dumapath\\AppData\\Local\\conda\\conda\\envs\\my_root\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "standard_inst = StandardScaler()\n",
    "standard_fit = standard_inst.fit(data)\n",
    "print(standard_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dumapath\\AppData\\Local\\conda\\conda\\envs\\my_root\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.96260083,  0.10340862, -0.14610313],\n",
       "       [ 0.70041383, -1.59782996, -0.01623368],\n",
       "       [-0.53561058, -0.73053186,  0.99025452],\n",
       "       [ 0.06367398, -1.19753853,  0.21103785],\n",
       "       [-2.22109841,  0.9373491 ,  0.5032441 ],\n",
       "       [ 0.0262187 ,  0.17012386, -1.28246077],\n",
       "       [-0.08614716,  1.60450148, -1.15259133],\n",
       "       [ 0.70041383,  0.770561  , -1.60713439],\n",
       "       [ 1.37460897,  0.80391862,  1.3473955 ],\n",
       "       [-0.985074  , -0.86396233,  1.15259133]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_inst.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardScaler removes the mean and scales the data to unit variance. However, the outliers have an influence when computing the empirical mean and standard deviation which shrink the range of the feature values\n",
    "\n",
    "StandardScaler therefore cannot guarantee balanced feature scales in the presence of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import quantile_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.99999900e-01,   4.99602166e-01,   9.99999998e-08],\n",
       "       [  9.99999900e-01,   9.99999998e-08,   5.00145715e-01],\n",
       "       [  4.99857000e-01,   9.99999998e-08,   9.99999900e-01],\n",
       "       [  9.99999900e-01,   9.99999998e-08,   5.00420420e-01],\n",
       "       [  9.99999998e-08,   9.99999900e-01,   5.00380380e-01],\n",
       "       [  9.99999900e-01,   5.00337072e-01,   9.99999998e-08],\n",
       "       [  5.00025025e-01,   9.99999900e-01,   9.99999998e-08],\n",
       "       [  9.99999900e-01,   5.00396500e-01,   9.99999998e-08],\n",
       "       [  9.99999900e-01,   9.99999998e-08,   5.00340340e-01],\n",
       "       [  4.99684300e-01,   9.99999998e-08,   9.99999900e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantile_transform(data,axis=1,n_quantiles=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"image.png\" style=\"height:150px\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<img src=\"image.png\" style=\"height:150px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"image.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "Image(url= \"image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normaliser \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Normalizer rescales the vector for each sample to have unit norm, independently of the distribution of the samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit-norm normalization\n",
    "\n",
    "When unit-norm normalization is applied, all the data in each profile are multiplied so that the length of the associated vector be equal to 1. \n",
    "The length of the vector is the square root of the sum of squares of all values.\n",
    "\n",
    "\n",
    "See the above figure that defines the L2 norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"image1.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"image1.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize samples individually to unit norm.\n",
    "\n",
    "Each sample (i.e. each row of the data matrix) with at least one non zero component is rescaled independently of other samples so that its norm (l1 or l2) equals one.\n",
    "\n",
    "This transformer is able to work both with dense numpy arrays and scipy.sparse matrix (use CSR format if you want to avoid the burden of a copy / conversion).\n",
    "\n",
    "Scaling inputs to unit norms is a common operation for text classification or clustering for instance. For instance the dot product of two l2-normalized TF-IDF vectors is the cosine similarity of the vectors and is the base similarity metric for the Vector Space Model commonly used by the Information Retrieval community.\n",
    "\n",
    "\n",
    "\n",
    "norm : ‘l1’, ‘l2’, or ‘max’, optional (‘l2’ by default)\n",
    "\n",
    "The norm to use to normalize each non zero sample.\n",
    "\n",
    "copy : boolean, optional, default True\n",
    "\n",
    "set to False to perform inplace row normalization and avoid a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalizer('l2').fit(data) # try 'l1' and 'l2' in place of 'max' default value is 'l2'\n",
    "normalized_X = scaler.transform(data)\n",
    "# normalized_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.77576597,  0.46367621,  0.42800881],\n",
       "       [ 0.83839757,  0.01047997,  0.54495842],\n",
       "       [ 0.47411902,  0.27236625,  0.83727402],\n",
       "       [ 0.72175793,  0.14893418,  0.67593203],\n",
       "       [ 0.01946524,  0.74941169,  0.66181812],\n",
       "       [ 0.74482871,  0.64872178,  0.15617376],\n",
       "       [ 0.51393806,  0.84494902,  0.14808385],\n",
       "       [ 0.74300557,  0.66870501,  0.02786271],\n",
       "       [ 0.63565376,  0.47349719,  0.60970871],\n",
       "       [ 0.35913023,  0.23599986,  0.902956  ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_X   # here all are positive we will have eve negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = np.random.randint(1,150,size=(50,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[136,  29,  45,  57],\n",
       "       [ 49,  78,  67, 117],\n",
       "       [ 79,  45, 123,   7],\n",
       "       [ 27,  75,  10,  54],\n",
       "       [ 31, 122,  74,  39],\n",
       "       [ 91,  24,  87, 129],\n",
       "       [139, 148,  34,  70],\n",
       "       [113,  68,  53,  83],\n",
       "       [146,  12,  65, 123],\n",
       "       [ 82, 122, 103, 129],\n",
       "       [  7, 118,  97,  32],\n",
       "       [ 70, 102,  38,  21],\n",
       "       [ 98,  73, 140, 139],\n",
       "       [ 68, 108, 130, 128],\n",
       "       [ 61, 140,  32, 106],\n",
       "       [ 67, 122,  12,  51],\n",
       "       [ 50, 106,  12,  41],\n",
       "       [140,  42, 148,  70],\n",
       "       [ 56,  35, 124,  77],\n",
       "       [ 11,  82, 109, 134],\n",
       "       [ 82,  62,  33,  65],\n",
       "       [  5,   5, 131,  50],\n",
       "       [ 69, 117,  27,  54],\n",
       "       [ 93,  82,  83, 142],\n",
       "       [ 48,  44,  68,  29],\n",
       "       [ 67,  91, 119,  62],\n",
       "       [120, 149,  33, 144],\n",
       "       [ 22,  57,   3,  41],\n",
       "       [143, 113,  32,  74],\n",
       "       [148,  98,  34, 105],\n",
       "       [100,  73,   8,  27],\n",
       "       [ 83,  32,  62,  64],\n",
       "       [ 37,  23, 143,  18],\n",
       "       [ 13,  48,  67,  82],\n",
       "       [ 31, 126,  26,  86],\n",
       "       [  1,   4,  48,  56],\n",
       "       [ 99,  56, 145,  86],\n",
       "       [ 96, 131,  41, 120],\n",
       "       [100, 130,  69,  88],\n",
       "       [ 60, 145,   7, 100],\n",
       "       [148,   2,  81,  59],\n",
       "       [103,  56,  88, 138],\n",
       "       [120, 119,  54,  27],\n",
       "       [102,  48,  28,  93],\n",
       "       [117,  92,  72,  82],\n",
       "       [142, 135, 105,  59],\n",
       "       [ 27, 122,  45, 146],\n",
       "       [ 51,  99, 113, 114],\n",
       "       [ 58, 143,   8,  36],\n",
       "       [124,  15, 136, 103]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(my_data,columns=['f1','f2','f3','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136</td>\n",
       "      <td>29</td>\n",
       "      <td>45</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>78</td>\n",
       "      <td>67</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>45</td>\n",
       "      <td>123</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>75</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>122</td>\n",
       "      <td>74</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>87</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>139</td>\n",
       "      <td>148</td>\n",
       "      <td>34</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>113</td>\n",
       "      <td>68</td>\n",
       "      <td>53</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>146</td>\n",
       "      <td>12</td>\n",
       "      <td>65</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>82</td>\n",
       "      <td>122</td>\n",
       "      <td>103</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>118</td>\n",
       "      <td>97</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>70</td>\n",
       "      <td>102</td>\n",
       "      <td>38</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>98</td>\n",
       "      <td>73</td>\n",
       "      <td>140</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>68</td>\n",
       "      <td>108</td>\n",
       "      <td>130</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>61</td>\n",
       "      <td>140</td>\n",
       "      <td>32</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>67</td>\n",
       "      <td>122</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>106</td>\n",
       "      <td>12</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>140</td>\n",
       "      <td>42</td>\n",
       "      <td>148</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>56</td>\n",
       "      <td>35</td>\n",
       "      <td>124</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11</td>\n",
       "      <td>82</td>\n",
       "      <td>109</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>82</td>\n",
       "      <td>62</td>\n",
       "      <td>33</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>131</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>69</td>\n",
       "      <td>117</td>\n",
       "      <td>27</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>93</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "      <td>68</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>67</td>\n",
       "      <td>91</td>\n",
       "      <td>119</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>120</td>\n",
       "      <td>149</td>\n",
       "      <td>33</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>22</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>143</td>\n",
       "      <td>113</td>\n",
       "      <td>32</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>148</td>\n",
       "      <td>98</td>\n",
       "      <td>34</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>100</td>\n",
       "      <td>73</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>83</td>\n",
       "      <td>32</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>143</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>67</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>31</td>\n",
       "      <td>126</td>\n",
       "      <td>26</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>99</td>\n",
       "      <td>56</td>\n",
       "      <td>145</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>96</td>\n",
       "      <td>131</td>\n",
       "      <td>41</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>100</td>\n",
       "      <td>130</td>\n",
       "      <td>69</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>60</td>\n",
       "      <td>145</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>103</td>\n",
       "      <td>56</td>\n",
       "      <td>88</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>120</td>\n",
       "      <td>119</td>\n",
       "      <td>54</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>102</td>\n",
       "      <td>48</td>\n",
       "      <td>28</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>117</td>\n",
       "      <td>92</td>\n",
       "      <td>72</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>142</td>\n",
       "      <td>135</td>\n",
       "      <td>105</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>27</td>\n",
       "      <td>122</td>\n",
       "      <td>45</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>51</td>\n",
       "      <td>99</td>\n",
       "      <td>113</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>58</td>\n",
       "      <td>143</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>124</td>\n",
       "      <td>15</td>\n",
       "      <td>136</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f1   f2   f3  Label\n",
       "0   136   29   45     57\n",
       "1    49   78   67    117\n",
       "2    79   45  123      7\n",
       "3    27   75   10     54\n",
       "4    31  122   74     39\n",
       "5    91   24   87    129\n",
       "6   139  148   34     70\n",
       "7   113   68   53     83\n",
       "8   146   12   65    123\n",
       "9    82  122  103    129\n",
       "10    7  118   97     32\n",
       "11   70  102   38     21\n",
       "12   98   73  140    139\n",
       "13   68  108  130    128\n",
       "14   61  140   32    106\n",
       "15   67  122   12     51\n",
       "16   50  106   12     41\n",
       "17  140   42  148     70\n",
       "18   56   35  124     77\n",
       "19   11   82  109    134\n",
       "20   82   62   33     65\n",
       "21    5    5  131     50\n",
       "22   69  117   27     54\n",
       "23   93   82   83    142\n",
       "24   48   44   68     29\n",
       "25   67   91  119     62\n",
       "26  120  149   33    144\n",
       "27   22   57    3     41\n",
       "28  143  113   32     74\n",
       "29  148   98   34    105\n",
       "30  100   73    8     27\n",
       "31   83   32   62     64\n",
       "32   37   23  143     18\n",
       "33   13   48   67     82\n",
       "34   31  126   26     86\n",
       "35    1    4   48     56\n",
       "36   99   56  145     86\n",
       "37   96  131   41    120\n",
       "38  100  130   69     88\n",
       "39   60  145    7    100\n",
       "40  148    2   81     59\n",
       "41  103   56   88    138\n",
       "42  120  119   54     27\n",
       "43  102   48   28     93\n",
       "44  117   92   72     82\n",
       "45  142  135  105     59\n",
       "46   27  122   45    146\n",
       "47   51   99  113    114\n",
       "48   58  143    8     36\n",
       "49  124   15  136    103"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['f1','f2','f3']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
